{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Agent System Skeleton\n",
        "\n",
        "This notebook demonstrates a **skeleton structure** of a multi-agent system in Python.  \n",
        "\n",
        "The goals of this notebook are:\n",
        "- Show the modular design of an agent that can handle queries.\n",
        "- Explain how caching, retrieval, safe calculations, and policy lookups are organized.\n",
        "\n"
      ],
      "metadata": {
        "id": "HSzWn-ou-IxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & Setup\n",
        "\n",
        "This section imports the required libraries and explains why each is needed:\n",
        "\n",
        "- `json` → for logging and storing structured data.\n",
        "- `time`, `datetime` → for timestamps and timing operations.\n",
        "- `hashlib` → for generating cache keys and run IDs.\n",
        "- `concurrent.futures` → for running tools with a timeout.\n",
        "- `re`, `ast` → for regex parsing and safe expression evaluation.\n",
        "- `sklearn.feature_extraction.text.TfidfVectorizer` → for converting text into numerical vectors (TF-IDF) to support retrieval.\n",
        "- `numpy` → for numerical operations like sorting and matrix multiplication.\n",
        "\n"
      ],
      "metadata": {
        "id": "uzEKK2fb-PcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import hashlib\n",
        "from datetime import datetime, UTC\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeout\n",
        "import re\n",
        "import ast\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "B1Gs7wO4-Sfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple In-Memory Cache\n",
        "\n",
        "`SimpleCache` provides a lightweight in-memory key-value store:\n",
        "\n",
        "- Avoids recomputing results for the same input.\n",
        "- Keys are generated using SHA256 hashes of the tool name + input arguments.\n",
        "- This is essential for performance in multi-agent systems where repeated queries occur.\n"
      ],
      "metadata": {
        "id": "YryOi1VX-WgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCache:\n",
        "    def __init__(self):\n",
        "        self._d = {}\n",
        "    def get(self, key):\n",
        "        return self._d.get(key)\n",
        "    def set(self, key, value):\n",
        "        self._d[key] = value\n"
      ],
      "metadata": {
        "id": "MBTvrQiY-XHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Callable with Timeout\n",
        "\n",
        "Some tools (like calculations or retrieval) might take too long.  \n",
        "\n",
        "- `run_with_timeout` uses `ThreadPoolExecutor` to limit execution time.\n",
        "- Ensures the agent does not hang indefinitely.\n",
        "- Supports retries and exponential backoff.\n"
      ],
      "metadata": {
        "id": "dnKbcsW2-ZTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_executor = ThreadPoolExecutor(max_workers=6)\n",
        "\n",
        "def run_with_timeout(fn, args=(), timeout=5):\n",
        "    fut = _executor.submit(fn, *args)\n",
        "    try:\n",
        "        return fut.result(timeout=timeout)\n",
        "    except FutureTimeout:\n",
        "        fut.cancel()\n",
        "        raise TimeoutError(\"timeout\")\n"
      ],
      "metadata": {
        "id": "c6V_Guiq-cC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculator: Safe Expression Evaluation\n",
        "\n",
        "- Uses Python's `ast` module to safely evaluate arithmetic expressions.\n",
        "- Only allows certain operators: `+ - * / % ** //`.\n",
        "- Prevents code injection since we do **not** use `eval`.\n",
        "- Supports both binary and unary operations.\n",
        "\n"
      ],
      "metadata": {
        "id": "DU7TVycA-iFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CiXXJH1S-Qvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ALLOWED_BINOPS = (ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Mod, ast.Pow, ast.FloorDiv)\n",
        "ALLOWED_UNARYOPS = (ast.UAdd, ast.USub)\n",
        "\n",
        "def safe_eval_expr(expr: str):\n",
        "    \"\"\"\n",
        "    Evaluate arithmetic expressions with numbers and + - * / % ** and parentheses.\n",
        "    \"\"\"\n",
        "    expr = expr.strip()\n",
        "    node = ast.parse(expr, mode='eval')\n",
        "\n",
        "    def _eval(n):\n",
        "        if isinstance(n, ast.Expression):\n",
        "            return _eval(n.body)\n",
        "        if isinstance(n, ast.Num):\n",
        "            return n.n\n",
        "        if isinstance(n, ast.BinOp):\n",
        "            if not isinstance(n.op, ALLOWED_BINOPS):\n",
        "                raise ValueError(\"Operator not allowed\")\n",
        "            left = _eval(n.left)\n",
        "            right = _eval(n.right)\n",
        "            if isinstance(n.op, ast.Add): return left + right\n",
        "            if isinstance(n.op, ast.Sub): return left - right\n",
        "            if isinstance(n.op, ast.Mult): return left * right\n",
        "            if isinstance(n.op, ast.Div): return left / right\n",
        "            if isinstance(n.op, ast.Mod): return left % right\n",
        "            if isinstance(n.op, ast.Pow): return left ** right\n",
        "            if isinstance(n.op, ast.FloorDiv): return left // right\n",
        "        if isinstance(n, ast.UnaryOp):\n",
        "            if not isinstance(n.op, ALLOWED_UNARYOPS):\n",
        "                raise ValueError(\"Unary op not allowed\")\n",
        "            val = _eval(n.operand)\n",
        "            if isinstance(n.op, ast.UAdd): return +val\n",
        "            if isinstance(n.op, ast.USub): return -val\n",
        "        raise ValueError(f\"Expression node not allowed: {type(n)}\")\n",
        "    return _eval(node)\n"
      ],
      "metadata": {
        "id": "di8rCedg-d64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retriever: TF-IDF over KB\n",
        "\n",
        "- Converts all text passages into TF-IDF vectors.\n",
        "- Computes cosine similarity to a query.\n",
        "- Returns top-k most relevant passages.\n",
        "- Essential for answering open-ended queries from the knowledge base.\n"
      ],
      "metadata": {
        "id": "4YVug4rM-lke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Retriever:\n",
        "    def __init__(self, passages):\n",
        "        self.passages = passages\n",
        "        texts = [p['text'] for p in passages]\n",
        "        self.vec = TfidfVectorizer().fit(texts)\n",
        "        self.mat = self.vec.transform(texts)\n",
        "    def retrieve(self, query, k=3):\n",
        "        qv = self.vec.transform([query])\n",
        "        scores = (self.mat @ qv.T).toarray()[:,0]\n",
        "        idx = np.argsort(scores)[::-1][:k]\n",
        "        return [{'score': float(scores[i]), **self.passages[i]} for i in idx if scores[i] > 0]\n"
      ],
      "metadata": {
        "id": "5-rpw0ev-oGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PolicyLookup\n",
        "\n",
        "- A shortcut for policy or FAQ queries.\n",
        "- Uses simple string matching on titles and keywords.\n",
        "- Useful for corporate-style queries like \"working hours\" or \"reimbursements\".\n"
      ],
      "metadata": {
        "id": "Zxw81NPt-qvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyLookup:\n",
        "    def __init__(self, passages):\n",
        "        self.kb = passages\n",
        "    def lookup(self, query):\n",
        "        results = []\n",
        "        q = query.lower()\n",
        "        for p in self.kb:\n",
        "            if p['title'].lower().startswith(\"company policy\") or 'working hours' in p['title'].lower():\n",
        "                if any(tok in q for tok in ['working hours','overtime','hours']):\n",
        "                    results.append(p)\n",
        "        for p in self.kb:\n",
        "            if p['title'].lower() in q or any(word in p['title'].lower() for word in q.split()):\n",
        "                if p not in results:\n",
        "                    results.append(p)\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "ZSYeC8Rp-rUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StringTools\n",
        "\n",
        "- Helper functions to extract numbers and percentages from text.\n",
        "- Useful for parsing queries like \"15% of 640\" or \"Compute 125 * 6\".\n"
      ],
      "metadata": {
        "id": "RQTCA3Ma-une"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StringTools:\n",
        "    @staticmethod\n",
        "    def extract_numbers(s):\n",
        "        return re.findall(r'[-+]?\\d*\\.?\\d+%?', s)\n",
        "    @staticmethod\n",
        "    def extract_percentages(s):\n",
        "        return re.findall(r'(\\d+(\\.\\d+)?)\\s*%', s)\n"
      ],
      "metadata": {
        "id": "7rAGz6EB-vH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Core\n",
        "\n",
        "The `Agent` class orchestrates the multi-agent system:\n",
        "\n",
        "- **Planner**: decides which tool(s) to use based on the query.\n",
        "- **Router**: calls the appropriate tool.\n",
        "- **Executor**: runs tools with retries and timeout.\n",
        "- **Cache**: avoids recomputation.\n",
        "- **Critic**: minimal check if an answer exists.\n",
        "- **Logger**: logs every stage with timestamps and run IDs.\n",
        "\n",
        "This design is modular: you can later add new tools or improve planning logic.\n"
      ],
      "metadata": {
        "id": "0IrpZWMI-ya1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, retriever, policy_lookup, cache=None):\n",
        "        self.retriever = retriever\n",
        "        self.policy_lookup = policy_lookup\n",
        "        self.cache = cache or SimpleCache()\n",
        "        self.logs = []\n",
        "    def plan(self, query):\n",
        "        if re.search(r'\\d', query) and re.search(r'[%\\+\\-\\*\\/]', query):\n",
        "            return ['calculator']\n",
        "        if any(word in query.lower() for word in ['policy','working hours','reimbursement','reimburse']):\n",
        "            return ['policylookup']\n",
        "        return ['retriever']\n",
        "    def run_tool_with_retries(self, tool_name, func, *args, retries=2, timeout=4):\n",
        "        cache_key = hashlib.sha256((tool_name + '|' + json.dumps(args, default=str)).encode()).hexdigest()\n",
        "        cached = self.cache.get(cache_key)\n",
        "        if cached:\n",
        "            return {'cached': True, 'result': cached, 'meta': {'retries': 0}}\n",
        "        last_exc = None\n",
        "        for attempt in range(1, retries+1):\n",
        "            try:\n",
        "                start = time.time()\n",
        "                res = run_with_timeout(func, args=args, timeout=timeout)\n",
        "                dur = (time.time()-start)*1000\n",
        "                self.cache.set(cache_key, res)\n",
        "                return {'cached': False, 'result': res, 'meta': {'retries': attempt-1, 'duration_ms': dur}}\n",
        "            except Exception as e:\n",
        "                last_exc = e\n",
        "                time.sleep(0.2 * attempt)\n",
        "        raise last_exc\n",
        "    def handle(self, query):\n",
        "        run_id = hashlib.sha1(query.encode()).hexdigest()[:8]\n",
        "        ts = datetime.now(UTC).isoformat().replace(\"+00:00\", \"Z\")\n",
        "        plan_steps = self.plan(query)\n",
        "        self.logs.append({'id': run_id, 'timestamp': ts, 'stage': 'plan', 'details': plan_steps})\n",
        "        final_answer = None\n",
        "        tool_calls = []\n",
        "        for step in plan_steps:\n",
        "            if step == 'calculator':\n",
        "                def calc_fn(q): return safe_eval_expr(q)\n",
        "                try:\n",
        "                    res = self.run_tool_with_retries('calculator', calc_fn, query)\n",
        "                    tool_calls.append({'tool': 'calculator', 'input': query, 'output': str(res['result'])})\n",
        "                    final_answer = str(res['result'])\n",
        "                except Exception as e:\n",
        "                    tool_calls.append({'tool': 'calculator', 'input': query, 'error': str(e)})\n",
        "            elif step == 'policylookup':\n",
        "                def pl_fn(q): return self.policy_lookup.lookup(q)\n",
        "                res = self.run_tool_with_retries('policylookup', pl_fn, query)\n",
        "                tool_calls.append({'tool': 'policylookup', 'input': query, 'output': [p['title'] for p in res['result']]})\n",
        "                if res['result']:\n",
        "                    final_answer = res['result'][0]['text']\n",
        "            elif step == 'retriever':\n",
        "                def r_fn(q): return self.retriever.retrieve(q, k=3)\n",
        "                res = self.run_tool_with_retries('retriever', r_fn, query)\n",
        "                tool_calls.append({'tool': 'retriever', 'input': query, 'output_count': len(res['result'])})\n",
        "                if res['result']:\n",
        "                    final_answer = res['result'][0]['text']\n",
        "\n",
        "        critic_ok = final_answer is not None\n",
        "        self.logs.append({'id': run_id, 'stage': 'tool_calls', 'details': tool_calls})\n",
        "        self.logs.append({'id': run_id, 'stage': 'critic', 'details': {'ok': critic_ok}})\n",
        "        output_record = {'id': run_id, 'timestamp': ts, 'query': query, 'final_output': final_answer}\n",
        "        self.logs.append({'id': run_id, 'stage': 'final', 'details': output_record})\n",
        "        return output_record\n",
        "\n",
        "    def dump_logs(self, path='logs.json'):\n",
        "        with open(path,'w') as f:\n",
        "            json.dump(self.logs, f, indent=2)\n"
      ],
      "metadata": {
        "id": "lumsr7Kl-zGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Base Loader\n",
        "\n",
        "- Parses `knowledgeBase.txt` into a list of documents.\n",
        "- Each document contains an `id`, `title`, and `text`.\n",
        "- This is a **naive parser**, depending on KB format `[DOC-X] ...`.\n"
      ],
      "metadata": {
        "id": "0mOSk8KK-03o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_kb_from_file(path='knowledgeBase.txt'):\n",
        "\n",
        "    docs = []\n",
        "    with open(path, 'r') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    parts = text.split('[DOC-')\n",
        "    for p in parts[1:]:\n",
        "        header, body = p.split(']',1)\n",
        "        id_num = header.strip()\n",
        "        title_line = body.strip().splitlines()[0]\n",
        "        title = title_line.replace('Title:','').strip() if 'Title:' in title_line else f'DOC-{id_num}'\n",
        "        txt = body.split('Text:')[-1].strip()\n",
        "        docs.append({'id': f'DOC-{id_num}', 'title': title, 'text': txt})\n",
        "    return docs\n"
      ],
      "metadata": {
        "id": "k8zLQowu-7hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage\n",
        "\n",
        "- Load KB\n",
        "- Initialize Retriever, PolicyLookup, and Agent\n",
        "- Run a sample query\n",
        "- Dump logs to file\n"
      ],
      "metadata": {
        "id": "hOsYba6N-9iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    kb = load_kb_from_file('knowledgeBase.txt')\n",
        "    retr = Retriever(kb)\n",
        "    pol = PolicyLookup(kb)\n",
        "    agent = Agent(retr, pol)\n",
        "    # Example queries:\n",
        "    q = \"What is LLUMO AI's core value proposition?\"\n",
        "    print(agent.handle(q))\n",
        "    agent.dump_logs()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSCZItmS-_Xb",
        "outputId": "ac672a07-0687-4eb2-8c35-dbdca6ddc98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '5e732532', 'timestamp': '2025-09-21T06:36:37.462473Z', 'query': \"What is LLUMO AI's core value proposition?\", 'final_output': 'LLUMO AI is an evaluation-first reliability layer for LLM apps. It focuses on automated scoring, actionable insights, and cost savings via prompt compression—helping teams ship trustworthy AI.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bXm2_TvS-5aK"
      }
    }
  ]
}